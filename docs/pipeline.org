** Config

I start off by defining some absolute directories that will be referred to throughout the script.  Hopefully I only have to change these 


#+BEGIN_SRC yaml :tangle ../workflow/config_base.yaml
  ---
  flag_file: &hst !Host {options: {midway2: "/project2", gardner: "/gpfs/data/xhe-lab/", desktop: "/run/media/nwknoblauch/Data"}}
  paths: 
    'DL': &dl  !Dep {host: *hst, pref:  null, path: { midway2: "/project2/xinhe/", gardner: "/gpfs/data/xhe-lab/", desktop: "/run/media/nwknoblauch/Data/"}}
    '1KG':     !Dep {host: *hst, pref: *dl, path: {midway2: &1kg "1kg/", gardner: *1kg , desktop: *1kg} }
    'BED':     !Dep {host: *hst, pref: *dl, path: {midway2: &bed "genomic_annotation/ptb_epigenetic/", gardner: *bed, desktop: "ptb_scratch/new_bed/"}}
    'L2':      !Dep {host: *hst, pref: *dl, path: {midway2: &l2 "genomic_annotation/L2/", gardner: *l2, desktop: "L2/"}}
    'ANNO':    !Dep {host: *hst, pref: *dl, path: {midway2: *l2 , gardner: *l2, desktop: *l2}}
    'WEIGHTS': !Dep {host: *hst, pref: *dl, path: {midway2: &weight "1kg/1000G_Phase3_weights_hm3_no_MHC/", gardner: *weight, desktop: *weight}} 
    'FRQF':    !Dep {host: *hst, pref: *dl, path: {midway2: &frq "1kg/1000G_Phase3_frq/", gardner: *frq, desktop: "1kg/1000G_Phase3_frq/"}} 
    'GWAS':    !Dep {host: *hst, pref: *dl, path: {midway2: &gwas "ptb/", gardner: *gwas, desktop: "gwas_data/gwas_sumstats/"}}
  envs:
    'r':    !Dep {host: *hst, pref:  null, path: { midway2: "../envs/eigenh5.yml", gardner: "../envs/eigenh5.yml", desktop: null }}
    'ldsc': !Dep {host: *hst, pref:  null, path: { midway2: "../envs/ldsc.yml", gardner: "../envs/ldsc.yml", desktop: "../envs/ldsc.yml" }}
#+END_SRC



#+BEGIN_SRC yaml :tangle ../workflow/base_model.yaml
- 'Coding_UCSCL2'
- 'Coding_UCSC.flanking.500L2'
- 'Conserved_LindbladTohL2'
- 'Conserved_LindbladToh.flanking.500L2'
- 'CTCF_HoffmanL2'
- 'CTCF_Hoffman.flanking.500L2'
- 'DGF_ENCODEL2'
- 'DGF_ENCODE.flanking.500L2'
- 'DHS_peaks_TrynkaL2'
- 'DHS_TrynkaL2'
- 'DHS_Trynka.flanking.500L2'
- 'Enhancer_AnderssonL2'
- 'Enhancer_Andersson.flanking.500L2'
- 'Enhancer_HoffmanL2'
- 'Enhancer_Hoffman.flanking.500L2'
- 'FetalDHS_TrynkaL2'
- 'FetalDHS_Trynka.flanking.500L2'
- 'H3K27ac_HniszL2'
- 'H3K27ac_Hnisz.flanking.500L2'
- 'H3K27ac_PGC2L2'
- 'H3K27ac_PGC2.flanking.500L2'
- 'H3K4me1_peaks_TrynkaL2'
- 'H3K4me1_TrynkaL2'
- 'H3K4me1_Trynka.flanking.500L2'
- 'H3K4me3_peaks_TrynkaL2'
- 'H3K4me3_TrynkaL2'
- 'H3K4me3_Trynka.flanking.500L2'
- 'H3K9ac_peaks_TrynkaL2'
- 'H3K9ac_TrynkaL2'
- 'H3K9ac_Trynka.flanking.500L2'
- 'Intron_UCSCL2'
- 'Intron_UCSC.flanking.500L2'
- 'PromoterFlanking_HoffmanL2'
- 'PromoterFlanking_Hoffman.flanking.500L2'
- 'Promoter_UCSCL2'
- 'Promoter_UCSC.flanking.500L2'
- 'Repressed_HoffmanL2'
- 'Repressed_Hoffman.flanking.500L2'
- 'SuperEnhancer_HniszL2'
- 'SuperEnhancer_Hnisz.flanking.500L2'
- 'TFBS_ENCODEL2'
- 'TFBS_ENCODE.flanking.500L2'
- 'Transcr_HoffmanL2'
- 'Transcr_Hoffman.flanking.500L2'
- 'TSS_HoffmanL2'
- 'TSS_Hoffman.flanking.500L2'
- 'UTR_3_UCSCL2'
- 'UTR_3_UCSC.flanking.500L2'
- 'UTR_5_UCSCL2'
- 'UTR_5_UCSC.flanking.500L2'
- 'WeakEnhancer_HoffmanL2'
- 'WeakEnhancer_Hoffman.flanking.500L2'
- 'GERP.NSL2'
- 'GERP.RSsup4L2'
- 'MAFbin1L2'
- 'MAFbin2L2'
- 'MAFbin3L2'
- 'MAFbin4L2'
- 'MAFbin5L2'
- 'MAFbin6L2'
- 'MAFbin7L2'
- 'MAFbin8L2'
- 'MAFbin9L2'
- 'MAFbin10L2'
- 'MAF_Adj_Predicted_Allele_AgeL2'
- 'MAF_Adj_LLD_AFRL2'
- 'Recomb_Rate_10kbL2'
- 'Nucleotide_Diversity_10kbL2'
- 'Backgrd_Selection_StatL2'
- 'CpG_Content_50kbL2'
- 'MAF_Adj_ASMCL2'
- 'GTEx_eQTL_MaxCPPL2'
- 'BLUEPRINT_H3K27acQTL_MaxCPPL2'
- 'BLUEPRINT_H3K4me1QTL_MaxCPPL2'
- 'BLUEPRINT_DNA_methylation_MaxCPPL2'
- 'synonymousL2'
- 'non_synonymousL2'
- 'Conserved_Vertebrate_phastCons46wayL2'
- 'Conserved_Vertebrate_phastCons46way.flanking.500L2'
- 'Conserved_Mammal_phastCons46wayL2'
- 'Conserved_Mammal_phastCons46way.flanking.500L2'
- 'Conserved_Primate_phastCons46wayL2'
- 'Conserved_Primate_phastCons46way.flanking.500L2'
- 'BivFlnkL2'
- 'BivFlnk.flanking.500L2'
- 'Human_Promoter_VillarL2'
- 'Human_Promoter_Villar.flanking.500L2'
- 'Human_Enhancer_VillarL2'
- 'Human_Enhancer_Villar.flanking.500L2'
- 'Ancient_Sequence_Age_Human_PromoterL2'
- 'Ancient_Sequence_Age_Human_Promoter.flanking.500L2'
- 'Ancient_Sequence_Age_Human_EnhancerL2'
- 'Ancient_Sequence_Age_Human_Enhancer.flanking.500L2'
- 'Human_Enhancer_Villar_Species_Enhancer_CountL2'
- 'Human_Promoter_Villar_ExACL2'
- 'Human_Promoter_Villar_ExAC.flanking.500L2'
#+END_SRC


#+BEGIN_SRC yaml :tangle ../workflow/annots.yaml
  ---
  baseline_model: 
    - Coding_UCSCL2
    - Conserved_LindbladTohL2
    - CTCF_HoffmanL2
    - DGF_ENCODEL2
    - DHS_peaks_TrynkaL2
    - DHS_TrynkaL2
    - Enhancer_AnderssonL2
    - Enhancer_HoffmanL2
    - FetalDHS_TrynkaL2
    - H3K27ac_HniszL2
    - H3K27ac_PGC2L2
    - H3K4me1_peaks_TrynkaL2
    - H3K4me1_TrynkaL2
    - H3K4me3_peaks_TrynkaL2
    - H3K4me3_TrynkaL2
    - H3K9ac_peaks_TrynkaL2
    - H3K9ac_TrynkaL2
    - Intron_UCSCL2
    - PromoterFlanking_HoffmanL2
    - Promoter_UCSCL2
    - Repressed_HoffmanL2
    - SuperEnhancer_HniszL2
    - TFBS_ENCODEL2
    - Transcr_HoffmanL2
    - TSS_HoffmanL2
    - UTR_3_UCSCL2
    - UTR_5_UCSCL2
    - WeakEnhancer_HoffmanL2
    - GERP.NSL2
    - GERP.RSsup4L2
    - MAFbin1L2
    - MAFbin2L2
    - MAFbin3L2
    - MAFbin4L2
    - MAFbin5L2
    - MAFbin6L2
    - MAFbin7L2
    - MAFbin8L2
    - MAFbin9L2
    - MAFbin10L2
    - MAF_Adj_Predicted_Allele_AgeL2
    - MAF_Adj_LLD_AFRL2
    - Recomb_Rate_10kbL2
    - Nucleotide_Diversity_10kbL2
    - Backgrd_Selection_StatL2
    - CpG_Content_50kbL2
    - MAF_Adj_ASMCL2
    - GTEx_eQTL_MaxCPPL2
    - BLUEPRINT_H3K27acQTL_MaxCPPL2
    - BLUEPRINT_H3K4me1QTL_MaxCPPL2
    - BLUEPRINT_DNA_methylation_MaxCPPL2
    - synonymousL2
    - non_synonymousL2
    - Conserved_Vertebrate_phastCons46wayL2
    - Conserved_Mammal_phastCons46wayL2
    - Conserved_Primate_phastCons46wayL2
    - BivFlnkL2
    - Human_Promoter_VillarL2
    - Human_Enhancer_VillarL2
    - Ancient_Sequence_Age_Human_PromoterL2
    - Ancient_Sequence_Age_Human_EnhancerL2
    - Human_Enhancer_Villar_Species_Enhancer_CountL2
    - Human_Promoter_Villar_ExACL2
  ptb_model:
    full: [
    'chip-seq-pooled-DSC1-dec-H3K27ac',
    'atac-seq-pooled-DSC2-dec-ATAC',
    'chip-seq-pooled-DSC1-ctr-H3K4me3',
    'atac-seq-pooled-DSC3-ctr-ATAC',
    'chip-seq-pooled-DSC3-ctr-H3K4me1',
    'chip-seq-pooled-DSC1-ctr-H3K4me1',
    'atac-seq-pooled-DSC1-ctr-ATAC',
    'chip-seq-reproducible-ctr-H3K4me3',
    'chip-seq-reproducible-dec-H3K27ac',
    'chip-seq-reproducible-dec-H3K4me3',
    'chip-seq-reproducible-dec-H3K4me1',
    'chip-seq-reproducible-ctr-H3K4me1',
    'atac-seq-reproducible-dec-ATAC',
    'chip-seq-reproducible-ctr-H3K27ac',
    'atac-seq-reproducible-ctr-ATAC',
    'chip-seq-dec_up-H3K4me1',
    'chip-seq-pooled-DSC3-dec-H3K4me3',
    'atac-seq-pooled-DSC2-ctr-ATAC',
    'chip-seq-dec_up-H3K4me3',
    'chip-seq-pooled-DSC3-ctr-H3K4me3',
    'atac-seq-dec_down-ATAC',
    'atac-seq-pooled-DSC3-dec-ATAC',
    'chip-seq-dec_up-H3K27ac',
    'chip-seq-dec_down-H3K4me3',
    'chip-seq-pooled-DSC2-ctr-H3K4me1',
    'chip-seq-pooled-DSC1-dec-H3K4me1',
    'chip-seq-pooled-DSC2-ctr-H3K27ac',
    'chip-seq-pooled-DSC2-dec-H3K4me1',
    'chip-seq-pooled-DSC1-dec-H3K4me3',
    'atac-seq-dec_up-ATAC',
    'chip-seq-pooled-DSC2-dec-H3K27ac',
    'chip-seq-pooled-DSC3-dec-H3K27ac',
    'chip-seq-dec_down-H3K27ac',
    'chip-seq-pooled-DSC3-ctr-H3K27ac',
    'chip-seq-dec_down-H3K4me1',
    'chip-seq-pooled-DSC3-dec-H3K4me1',
    'chip-seq-pooled-DSC2-dec-H3K4me3',
    'chip-seq-pooled-DSC2-ctr-H3K4me3',
    'atac-seq-pooled-DSC1-dec-ATAC',
    'chip-seq-pooled-DSC1-ctr-H3K27ac']
    reproducible: [
    'chip-seq-reproducible-ctr-H3K4me3',
    'chip-seq-reproducible-dec-H3K27ac',
    'chip-seq-reproducible-dec-H3K4me3',
    'chip-seq-reproducible-dec-H3K4me1',
    'chip-seq-reproducible-ctr-H3K4me1',
    'atac-seq-reproducible-dec-ATAC',
    'chip-seq-reproducible-ctr-H3K27ac',
    'atac-seq-reproducible-ctr-ATAC'
    ]

#+END_SRC

#+BEGIN_SRC snakemake :tangle ../workflow/snakefile


  import os
  import yaml
  from yaml import Loader
  from typing import Any,IO


  def host_loader(loader: yaml.loader.Loader,node: yaml.Node) -> Any:
        fields = loader.construct_mapping(node,deep=True)
        options=fields['options']
        # print([options[name] for name in options.keys()])
        ret_opt = [name for name in options.keys() if os.path.exists(options[name])]
        # print(ret_opt)
        return ret_opt[0]


  def dep_loader(loader: yaml.loader.Loader,node: yaml.Node) -> Any:
        options = loader.construct_mapping(node,deep=True)
        host = options['host']
        pref = options['pref']
        # print(pref)
        host =options['host']
        path = options['path']
        full_path = pref+path[host] if pref is not None else path[host]
        return full_path



  yaml.Loader.add_constructor('!Host', host_loader)
  yaml.Loader.add_constructor('!Dep', dep_loader)



  with open("../workflow/config_base.yaml") as stream:
        config=yaml.load(stream)

  config_d = config['paths']
  config_e = config['envs']


  with open("annots.yaml", 'r') as stream:
      all_annot = yaml.safe_load(stream)
      #(all_annot)
  wildcard_constraints:
      chrom="\d+"

  localrules: all, get_hm3_snplist,get_plinkfiles,get_frq,get_weights


  include: "dl_snakefile"
  include: "gwas_snakefile"
  rule all:
      input:
          config_d['GWAS'] +"ldsc_input/ptb_gwas.sumstats.gz",
          "reproducible.results"



#+END_SRC

** Downloading files

The first step is to download some LD score regression stuff from the web. In particular we want a gzipped tarball of the hapmap 3 SNPs.

#+BEGIN_SRC snakemake :tangle ../workflow/dl_snakefile



  rule get_gest_dur_gwas:
      output:
          temp(config_d['GWAS']+"Fetal_gest_duration_NComms2019.txt.gz")
      shell:
          "wget http://mccarthy.well.ox.ac.uk/publications/2019/EggGestationalDuration_NatureCommunications/Fetal_gest_duration_NComms2019.txt.gz"


  rule get_hm3_snplist:
      output:
          temp(config_d['DL'] +"hapmap3_snps.tgz")
      shell:
          "wget https://data.broadinstitute.org/alkesgroup/LDSCORE/hapmap3_snps.tgz -O {output}"
#+END_SRC

Next we'll unzip the files and put them somewhere on disk.

#+BEGIN_SRC snakemake :tangle ../workflow/dl_snakefile

rule gunzip_hm3:
    input:
        rules.get_hm3_snplist.output
    params:
        dld=config_d['1KG']
    output:
        expand(config_d['1KG']+"hapmap3_snps/"+"hm.{chrom}.snp",chrom=range(1,23))
    shell:
        "tar -C {params.dld} -xvzf {input}"


#+END_SRC

The rsids don't come with coordinates, and we don't have coordinates for our GWAS data, so we'll use the ~SNPlocs.Hsapiens.dbSNP144.GRCh37~ package 
to get the coordinates corresponding to these rsids.  Also note that we won't be able to get all of them, as some rsids have been merged by NCBI.

#+BEGIN_SRC R :tangle ../scripts/rsid2loc.R

  library(tidyverse)
  library(ldmap)


  input_f <- snakemake@input[["input"]]
  output_f <- snakemake@output[["output"]]
  input_ids <- EigenH5::fast_str2int(scan(input_f, what = character()), prefix = "rs")
  input_ids <- input_ids[!is.na(input_ids)]
  BSgenome::snpsById(SNPlocs.Hsapiens.dbSNP144.GRCh37::SNPlocs.Hsapiens.dbSNP144.GRCh37,
                     ids = input_ids,
                     ifnotfound = "warn") %>% as_tibble() %>% 
      dplyr::rename(chrom = seqnames, rsid = RefSNP_id) %>%
      dplyr::mutate(chrom = as.integer(chrom),
                    rsid = rsid) %>%
      select(-strand) %>%
      readr::write_tsv(output_f)

#+END_SRC

#+RESULTS:

#+BEGIN_SRC snakemake :tangle ../workflow/dl_snakefile

  # rule snp2coord:
  #     input:
  #         inputf=config_d['1KG']+"hapmap3_snps/"+"hm.{chrom}.snp"
  #     output:
  #         outputf=config_d['1KG']+"hapmap3_snps/"+"hm.{chrom}.tsv.gz"
  #     script:
  #         "../scripts/rsid2loc.R"
    
#+END_SRC

** Munging the GWAS data

Unfortunately I don't have a remote source for the gwas summary statistics I can point you to, so we'll just pretend like you know
how to get to `meta.stat` the PTB gwas file.  First thing is to convert it to HDF5 for easier read/write of subsets


#+BEGIN_SRC R :tangle ../scripts/gwas2h5.R

  library(tidyverse)
  library(EigenH5)
  library(readr)
  library(ldmap)


  mc <- cols(
      rsid = col_character(),
      chrom = col_integer(),
      pos = col_double(),
      A1 = col_character(),
      A2 = col_character(),
      N = col_double(),
      freq = col_double(),
      beta = col_double(),
      se = col_double(),
      pval = col_double(),
      Q = col_double(),
      het = col_double(),
      N.local = col_double(),
      freq.local = col_double(),
      beta.local = col_double(),
      se.local = col_double(),
      pval.local = col_double(),
      N.23andMe = col_double(),
      freq.23andMe = col_double(),
      beta.23andMe = col_double(),
      se.23andMe = col_double(),
      pval.23andMe = col_double()
  )


  input_f <- snakemake@input[["inputf"]]
  output_f <- snakemake@output[["outputf"]]


  callback_fun <- function(df, filename, datapath, ...){
    write_df_h5(
      df = dplyr::slice(
                    dplyr::mutate(df,
                                  ref = fast_str2ascii(A2),
                                  alt = fast_str2ascii(A1),
                                  snp_struct =
                                    new_ldmap_snp(chrom, pos, ref, alt),
                                  rsid = fast_str2int(rsid, prefix = "rs"),
                                  ),
                    rank.ldmap_snp(snp_struct)),
      filename = filename, datapath = datapath, ... = ...)
  }

  stopifnot(!is.null(input_f),
            !is.null(output_f),
            file.exists(input_f),
            !file.exists(output_f))

  delim2h5(input_f,
           output_file = output_f,
           h5_args = list(datapath = "snp"),
           delim = "\t",
           col_names = names(mc$cols),
           skip = 1L,
           callback_fun = callback_fun,
           col_types = mc,
           progress = TRUE,
           chunk_size = 150000)

  chrom_vec <- read_vector_h5v(output_f, "snp/chrom", i = integer())
  chrom_df <- rle2offset(chrom_vec) %>%
      dplyr::rename(chrom = value)
  write_df_h5(chrom_df,output_f,"chrom_offset")
#+END_SRC




#+BEGIN_SRC snakemake :tangle ../workflow/gwas_snakefile

  rule ptb_gwas2h5:
      input:
          inputf=config_d['GWAS']+"meta.stat"
      output:
          outputf=config_d['GWAS'] +"ptb_gwas.h5"
      conda:
          config_e['r']
      script:
          "../scripts/gwas2h5.R"

#+END_SRC



Next is to write some code to pull out the indices with the matching rsids (using coordinates, not rsid)


#+BEGIN_SRC R :tangle ../scripts/index_gwas.R

  library(tidyverse)
  library(EigenH5)
  library(readr)
  library(ldmap)
  ## setwd("~/Dropbox/Repos/ldsc/workflow/")
  ##   load("~/Dropbox/Repos/ldsc/workflow/tf.RData")

    input_f <- snakemake@input[["inputf"]]
    index_f <-  snakemake@input[["indexf"]]
    chrom <- snakemake@params[["chrom"]]
    stopifnot(!is.null(chrom))
    schrom <- as.integer(chrom)
    output_f <- snakemake@output[["outputf"]]


    ind_spec <- cols_only(
      CHR = col_integer(),
      BP = col_double(),
      SNP = col_character()
    )

    gwas_type <- if_else(
      is.null(snakemake@params[["gwas_t"]]),
      "",
      paste0(".", snakemake@params[["gwas_t"]])
    )


    beta_col <- glue::glue("beta{gwas_type}")
    se_col <- glue::glue("se{gwas_type}")
    N_col <- glue::glue("N{gwas_type}")
    P_col <- glue::glue("pval{gwas_type}")

    sel_cols <- c("snp_struct",
                  beta_col,
                  "A1",
                  "A2",
                  se_col,
                  N_col,
                  P_col)

    sel_cols <- stringr::str_replace(
                           sel_cols,
                           "\\.$",
                           "")

    index_df <- vroom::vroom(
                         index_f,
                         delim = "\t",
                         col_types = ind_spec
                       )  %>% 
      rename(chrom=CHR,rsid=SNP,pos=BP)
      nr_index_df <- nrow(index_df)

    chrom_df <- read_tibble_h5(input_f, "chrom_offset", list()) %>%
      filter(chrom == schrom) %>% mutate(offset = as.integer(offset), datasize = as.integer(datasize)) %>% 
      arrange(offset)

    jdf <- pmap_dfr(chrom_df, function(chrom, datasize, offset) {
  #    subset_l <- seq(offset + 1, length.out = datasize)
      input_i <- EigenH5::read_df_h5(filename = input_f,
                              datapath = "snp",
                                subcols = sel_cols,
                                offset=offset,
                                datasize=datasize) %>%
        mutate(subset = (1:n()) + offset)

        inner_join(index_df,  bind_cols(input_i,ldmap::ldmap_snp_2_dataframe(input_i$snp_struct)))
    })

                                          #%>% mutate(snp_struct = as_ldmap_snp(snp_struct))  %>%
  stopifnot(all(jdf$chrom == schrom))
  stopifnot(nrow(jdf)>0)
  ## stopifnot(nrow(jdf) == nr_index_df)

    jdf  %>% rename(beta =  {{beta_col}},
                    se =  {{se_col}},
                    N =  {{N_col}}) %>%
      dplyr::distinct(rsid, .keep_all = TRUE) %>% 
      dplyr::transmute(SNP = rsid, N = N, Z = beta / se, A1 = A1, A2 = A2,P=pval) %>%
      vroom::vroom_write(output_f,delim = "\t")
#+END_SRC

#+BEGIN_SRC R :tangle ../scripts/gen_ldsc_sumstats.R
library(vroom)
library(magrittr)

 input_f <- snakemake@input[["inputf"]]
 output <- snakemake@output[["outputf"]]

 vroom::vroom(input_f,delim="\t") %>% vroom_write(output,delim="\t")


#+END_SRC


#+BEGIN_SRC snakemake :tangle ../workflow/gwas_snakefile

  rule indexgwas2h5:
      input:
          inputf=config_d['GWAS'] +"ptb_gwas.h5",
          indexf=config_d['L2'] +"baseline/baselineLD.{chrom}.l2.ldscore.gz"
      params:
          chrom="{chrom}"
      output:
          outputf=temp(config_d['GWAS'] +"hm3_index/ptb_gwas_hm_chr{chrom}.tsv")
      conda:
          config_e['r']
      script:
          "../scripts/index_gwas.R"

  rule prep_ldsc_sumstsat:
      input:
          inputf=expand(config_d['GWAS'] +"hm3_index/ptb_gwas_hm_chr{chrom}.tsv",chrom=range(1,23))
      params:
          gwas_t=""
      output:
          outputf=temp(config_d['GWAS'] +"ldsc_input/pre_ptb_gwas.sumstats.gz")
      conda:
          config_e['r']
      script:
          "../scripts/gen_ldsc_sumstats.R"


  rule check_ldsc_sumstat:
      input:
          config_d['GWAS'] +"ldsc_input/pre_ptb_gwas.sumstats.gz"
      params:
          outputf=config_d['GWAS'] +"ldsc_input/ptb_gwas"
      conda:
          config_e['ldsc']
      output:
          outputf=config_d['GWAS'] +"ldsc_input/ptb_gwas.sumstats.gz",
      log:
          logf=config_d['GWAS'] +"ldsc_input/ptb_gwas.log"
      shell:
          "python2 ../munge_sumstats.py --sumstats {input} --out {params.outputf}"
#+END_SRC

#+BEGIN_SRC bash :session rcc2 :dir /ssh:rcc2:/project2/xinhe/software/ldsc/workflow/
. "/project2/xinhe/software/miniconda3/etc/profile.d/conda.sh"
conda activate cause_gwas
snakemake -n


#+END_SRC

** Running LDSC

#+BEGIN_SRC snakemake :tangle ../workflow/dl_snakefile

  rule get_cadd:
      output:
          temp(config_d["DL"]+"whole_genome_SNVs_inclAnno.tsv.gz")
      shell:
          "wget https://krishna.gs.washington.edu/download/CADD/v1.4/GRCh37/whole_genome_SNVs_inclAnno.tsv.gz -O {output}"

  rule get_spidex:
      output:
          temp(config_d["DL"]+"hg19_spidex.zip")
      shell:
          "wget http://www.openbioinformatics.org/annovar/download/IlvUMvrpPT/hg19_spidex.zip -O {output}"
  rule get_baseline_model:
      output:
          temp(config_d['DL']+"1000G_Phase3_baselineLD_v2.2_ldscores.tgz")
      shell:
          "wget https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase3_baselineLD_v2.2_ldscores.tgz -O {output}"

  rule get_weights:
      output:
          temp(config_d["DL"]+"1000G_Phase3_weights_hm3_no_MHC.tgz")
      shell:
          "wget https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase3_weights_hm3_no_MHC.tgz -O {output}"

  rule gunzip_weights:
      input:
          config_d["DL"]+"1000G_Phase3_weights_hm3_no_MHC.tgz"
      output:
          ldfiles = expand(config_d['WEIGHTS'] +"weights.hm3_noMHC.{chrom}.l2.ldscore.gz",chrom=range(1,23))
      params:
          W=config_d['1KG']
      shell:
          "tar -xvzf {input} -C {params.W}"        

  rule get_frq:
      output:
          temp(config_d['DL']+"1000G_Phase3_frq.tgz")
      shell:
          "wget https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase3_frq.tgz -O {output}"


  rule get_plinkfiles:
      output:
          temp(config_d['DL'] +"1000G_Phase3_plinkfiles.tgz")
      shell:
          "wget https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase3_plinkfiles.tgz -O {output}"

  rule gunzip_plinkfiles:
      input:
          config_d['DL'] +"1000G_Phase3_plinkfiles.tgz"
      output:
          fam_files = expand(config_d['1KG'] +"1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.fam",chrom=range(1,23)),
          bim_files = expand(config_d['1KG'] +"1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bim",chrom=range(1,23)),
          bed_files = expand(config_d['1KG'] +"1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bed",chrom=range(1,23))
      params:
          KG=config_d['1KG']
      shell:
          "tar -xvzf {input} -C {params.KG}"

  rule gunzip_frqf:
      input:
          config_d['DL'] +"1000G_Phase3_frq.tgz"
      output:
          fam_files = expand(config_d['FRQF'] +"1000G.EUR.QC.{chrom}.frq",chrom=range(1,23)),
      params:
          KG=config_d['1KG']
      shell:
          "tar -xvzf {input} -C {params.KG}"


  rule gunzip_baseline:
      input:
          config_d['DL'] +"1000G_Phase3_baselineLD_v2.2_ldscores.tgz"
      output:
          ldfiles = expand(config_d['L2'] +"baseline/baselineLD.{chrom}.l2.ldscore.gz",chrom=range(1,23)),
          annotf = expand(config_d['L2'] +"baseline/baselineLD.{chrom}.annot.gz",chrom=range(1,23)),
          m50 = expand(config_d['L2'] +"baseline/baselineLD.{chrom}.l2.M_5_50",chrom=range(1,23))
      params:
          L2=config_d['L2']
      shell:
          "tar -xvzf {input} -C {params.L2}/baseline"



  rule unzip_annot:
      input:
          config_d['BED'] + "{annot}.bed.gz"
      output:
          temp(config_d['BED'] + "{annot}.bed")
      wildcard_constraints:
          annot="[^/]+"
      shell:
          "gzip -cd {input} > {output}"


  rule make_annot:
      input:
          anno_bed=config_d['BED'] +"{annot}.bed",
          bim=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bim"
      output:
          annot = config_d['L2'] +"{annot}.{chrom}.annot.gz"
      params:
          anno_name='{annot}'
      conda:
          config_e['ldsc']
      shell:
          "python2 ../make_annot.py --bed-file {input.anno_bed} --bimfile {input.bim} --annot-file {output.annot} --annot-name {params.anno_name}"

  rule pull_rsid:
      input:
          config_d["L2"]+"baseline/baselineLD.{chrom}.l2.ldscore.gz"
      output:
          temp(config_d["L2"]+"snplist/{chrom}.snplist.txt")
      shell:
          "zcat {input} | cut -f 2 | tail -n +2 > {output}"



  rule cmp_ldscores:
      input:
          anno_bed=config_d['L2'] +"{annot}.{chrom}.annot.gz",
          snplistf=config_d["L2"]+"snplist/{chrom}.snplist.txt",
          bim=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bim",
          bed=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bed",
          fam=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.fam"
      output:
          l2=config_d['L2']+"{annot}.{chrom}.l2.M",
          l2M_50=config_d['L2']+"{annot}.{chrom}.l2.M_5_50",
          l2gz=config_d['L2']+"{annot}.{chrom}.l2.ldscore.gz"
      params:
          plink=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}",
          odir=config_d['L2']+"{annot}.{chrom}"
      # wildcard_constraints:
      #     annot="[^/]"
      conda:
          config_e['ldsc']
      shell:
          "python2 ../ldsc.py --l2 --bfile {params.plink} --print-snps {input.snplistf} --ld-wind-cm 1 --thin-annot --annot {input.anno_bed} --out {params.odir} "

  # rule cmp_ldscores_baseline:
  #     input:
  #         anno_bed=config_d['L2'] +"baseline/baselineLD.{chrom}.annot.gz",
  #         bim=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bim",
  #         bed=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.bed",
  #         fam=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}.fam"
  #     output:
  #         l2=config_d['L2']+"baselineLD/{annot}.{chrom}.l2.M",
  #         l2M_50=config_d['L2']+"baselineLD/{annot}.{chrom}.l2.M_5_50",
  #         l2gz=config_d['L2']+"baselineLD/{annot}.{chrom}.l2.ldscore.gz"
  #     params:
  #         plink=config_d['1KG'] + "1000G_EUR_Phase3_plink/1000G.EUR.QC.{chrom}",
  #         odir=config_d['L2']+"baselineLD/{annot}.{chrom}"
  #     conda:
  #         config_e['ldsc']
  #     shell:
  #         "python2 ../ldsc.py --l2 --bfile {params.plink} --ld-wind-cm 1 --annot {input.anno_bed}  --out {params.odir} "

  # def ldsc_fun(wildcards):
  #     {tchrom: expand(config_d['L2'] +"{anno_name}.{chrom}.l2.ldscore.gz",chrom=[tchrom],anno_name=['baseline' *all_annot[wildcards.anno_name]]) for tchrom in range(1,23)}

  # rule check_ldsc:
  #     input:
  #         unpack(ldsc_fun)
  #     output:
  #         temp("{anno_name}.check")
  #     script:
  #         "../scripts/check_ldscfiles.R"
#+END_SRC

#+BEGIN_SRC R :tangle ../scripts/check_ldscfiles.R

  library(vroom)
  library(tidyverse)
  library(fs)

  save.image("wsl.RDS")
  stop()
  setwd("~/Dropbox/Repos/ldsc/workflow")
  load("wsl.RDS")

  ## yam
  ## l_file <- yaml::yaml.load_file("../workflow/annots.yaml")

  feat_list <- snakemake@params[["features"]]
  baseline_feat <- snakemake@params[["baseline_features"]]
  annot_name <- snakemake@params[["annot_name"]]
  l2dir <- snakemake@params[["L2"]]

  stopifnot(!is.null(feat_list),!is.null(baseline_feat),!is.null(annot_name),!is.null(l2dir))

#+END_SRC

#+BEGIN_SRC R :tangle ../scripts/check_ldscfiles.R
   file_df <- tibble::as_tibble(expand.grid(feature = feat_list, chrom = 1:22,stringsAsFactors = FALSE)) %>%
    dplyr::mutate(
             path = fs::path(l2dir,
                             paste0( feature, ".", chrom, ".l2.ldscore.gz")),
             annot_path = fs::path(l2dir,
                             paste0( feature, ".", chrom, ".annot.gz")),
             baseline_path = fs::path(l2dir,"baseline/", paste0("baselineLD.", chrom, ".l2.ldscore.gz")),
             baseline_annot_path = fs::path(l2dir,"baseline/", paste0("baselineLD.", chrom, ".annot.gz")),
             new_path = fs::path(l2dir,"new_baseline/", paste0(annot_name,".", chrom, ".l2.ldscore.gz")),
             new_annot_path = fs::path(l2dir,"new_baseline/", paste0(annot_name,".", chrom, "annot.gz"))
                 )





  stopifnot(all(fs::file_exists(c(file_df$path,file_df$baseline_path,file_df$annot_path,file_df$baseline_annot_path))))
#+END_SRC

#+BEGIN_SRC R :tangle ../scripts/check_ldscfiles.R
  spec <- cols(
    CHR = col_skip(),
    SNP = col_skip(),
    BP = col_skip(),
    L2 = col_double()
  )
  spec_base <- cols(
    CHR = col_double(),
    SNP = col_character(),
    BP = col_double(),
    baseL2 = col_double(),
    Coding_UCSCL2 = col_double(),
    Coding_UCSC.flanking.500L2 = col_double(),
    Conserved_LindbladTohL2 = col_double(),
    Conserved_LindbladToh.flanking.500L2 = col_double(),
    CTCF_HoffmanL2 = col_double(),
    CTCF_Hoffman.flanking.500L2 = col_double(),
    DGF_ENCODEL2 = col_double(),
    DGF_ENCODE.flanking.500L2 = col_double(),
    DHS_peaks_TrynkaL2 = col_double(),
    DHS_TrynkaL2 = col_double(),
    DHS_Trynka.flanking.500L2 = col_double(),
    Enhancer_AnderssonL2 = col_double(),
    Enhancer_Andersson.flanking.500L2 = col_double(),
    Enhancer_HoffmanL2 = col_double(),
    Enhancer_Hoffman.flanking.500L2 = col_double(),
    FetalDHS_TrynkaL2 = col_double(),
    FetalDHS_Trynka.flanking.500L2 = col_double(),
    H3K27ac_HniszL2 = col_double(),
    H3K27ac_Hnisz.flanking.500L2 = col_double(),
    H3K27ac_PGC2L2 = col_double(),
    H3K27ac_PGC2.flanking.500L2 = col_double(),
    H3K4me1_peaks_TrynkaL2 = col_double(),
    H3K4me1_TrynkaL2 = col_double(),
    H3K4me1_Trynka.flanking.500L2 = col_double(),
    H3K4me3_peaks_TrynkaL2 = col_double(),
    H3K4me3_TrynkaL2 = col_double(),
    H3K4me3_Trynka.flanking.500L2 = col_double(),
    H3K9ac_peaks_TrynkaL2 = col_double(),
    H3K9ac_TrynkaL2 = col_double(),
    H3K9ac_Trynka.flanking.500L2 = col_double(),
    Intron_UCSCL2 = col_double(),
    Intron_UCSC.flanking.500L2 = col_double(),
    PromoterFlanking_HoffmanL2 = col_double(),
    PromoterFlanking_Hoffman.flanking.500L2 = col_double(),
    Promoter_UCSCL2 = col_double(),
    Promoter_UCSC.flanking.500L2 = col_double(),
    Repressed_HoffmanL2 = col_double(),
    Repressed_Hoffman.flanking.500L2 = col_double(),
    SuperEnhancer_HniszL2 = col_double(),
    SuperEnhancer_Hnisz.flanking.500L2 = col_double(),
    TFBS_ENCODEL2 = col_double(),
    TFBS_ENCODE.flanking.500L2 = col_double(),
    Transcr_HoffmanL2 = col_double(),
    Transcr_Hoffman.flanking.500L2 = col_double(),
    TSS_HoffmanL2 = col_double(),
    TSS_Hoffman.flanking.500L2 = col_double(),
    UTR_3_UCSCL2 = col_double(),
    UTR_3_UCSC.flanking.500L2 = col_double(),
    UTR_5_UCSCL2 = col_double(),
    UTR_5_UCSC.flanking.500L2 = col_double(),
    WeakEnhancer_HoffmanL2 = col_double(),
    WeakEnhancer_Hoffman.flanking.500L2 = col_double(),
    GERP.NSL2 = col_double(),
    GERP.RSsup4L2 = col_double(),
    MAFbin1L2 = col_double(),
    MAFbin2L2 = col_double(),
    MAFbin3L2 = col_double(),
    MAFbin4L2 = col_double(),
    MAFbin5L2 = col_double(),
    MAFbin6L2 = col_double(),
    MAFbin7L2 = col_double(),
    MAFbin8L2 = col_double(),
    MAFbin9L2 = col_double(),
    MAFbin10L2 = col_double(),
    MAF_Adj_Predicted_Allele_AgeL2 = col_double(),
    MAF_Adj_LLD_AFRL2 = col_double(),
    Recomb_Rate_10kbL2 = col_double(),
    Nucleotide_Diversity_10kbL2 = col_double(),
    Backgrd_Selection_StatL2 = col_double(),
    CpG_Content_50kbL2 = col_double(),
    MAF_Adj_ASMCL2 = col_double(),
    GTEx_eQTL_MaxCPPL2 = col_double(),
    BLUEPRINT_H3K27acQTL_MaxCPPL2 = col_double(),
    BLUEPRINT_H3K4me1QTL_MaxCPPL2 = col_double(),
    BLUEPRINT_DNA_methylation_MaxCPPL2 = col_double(),
    synonymousL2 = col_double(),
    non_synonymousL2 = col_double(),
    Conserved_Vertebrate_phastCons46wayL2 = col_double(),
    Conserved_Vertebrate_phastCons46way.flanking.500L2 = col_double(),
    Conserved_Mammal_phastCons46wayL2 = col_double(),
    Conserved_Mammal_phastCons46way.flanking.500L2 = col_double(),
    Conserved_Primate_phastCons46wayL2 = col_double(),
    Conserved_Primate_phastCons46way.flanking.500L2 = col_double(),
    BivFlnkL2 = col_double(),
    BivFlnk.flanking.500L2 = col_double(),
    Human_Promoter_VillarL2 = col_double(),
    Human_Promoter_Villar.flanking.500L2 = col_double(),
    Human_Enhancer_VillarL2 = col_double(),
    Human_Enhancer_Villar.flanking.500L2 = col_double(),
    Ancient_Sequence_Age_Human_PromoterL2 = col_double(),
    Ancient_Sequence_Age_Human_Promoter.flanking.500L2 = col_double(),
    Ancient_Sequence_Age_Human_EnhancerL2 = col_double(),
    Ancient_Sequence_Age_Human_Enhancer.flanking.500L2 = col_double(),
    Human_Enhancer_Villar_Species_Enhancer_CountL2 = col_double(),
    Human_Promoter_Villar_ExACL2 = col_double(),
    Human_Promoter_Villar_ExAC.flanking.500L2 = col_double()
  )



  anno_cols <- cols(
    CHR = col_double(),
    BP = col_double(),
    SNP = col_character(),
    CM = col_double(),
    base = col_double(),
    Coding_UCSC = col_double(),
    Coding_UCSC.flanking.500 = col_double(),
    Conserved_LindbladToh = col_double(),
    Conserved_LindbladToh.flanking.500 = col_double(),
    CTCF_Hoffman = col_double(),
    CTCF_Hoffman.flanking.500 = col_double(),
    DGF_ENCODE = col_double(),
    DGF_ENCODE.flanking.500 = col_double(),
    DHS_peaks_Trynka = col_double(),
    DHS_Trynka = col_double(),
    DHS_Trynka.flanking.500 = col_double(),
    Enhancer_Andersson = col_double(),
    Enhancer_Andersson.flanking.500 = col_double(),
    Enhancer_Hoffman = col_double(),
    Enhancer_Hoffman.flanking.500 = col_double(),
    FetalDHS_Trynka = col_double(),
    FetalDHS_Trynka.flanking.500 = col_double(),
    H3K27ac_Hnisz = col_double(),
    H3K27ac_Hnisz.flanking.500 = col_double(),
    H3K27ac_PGC2 = col_double(),
    H3K27ac_PGC2.flanking.500 = col_double(),
    H3K4me1_peaks_Trynka = col_double(),
    H3K4me1_Trynka = col_double(),
    H3K4me1_Trynka.flanking.500 = col_double(),
    H3K4me3_peaks_Trynka = col_double(),
    H3K4me3_Trynka = col_double(),
    H3K4me3_Trynka.flanking.500 = col_double(),
    H3K9ac_peaks_Trynka = col_double(),
    H3K9ac_Trynka = col_double(),
    H3K9ac_Trynka.flanking.500 = col_double(),
    Intron_UCSC = col_double(),
    Intron_UCSC.flanking.500 = col_double(),
    PromoterFlanking_Hoffman = col_double(),
    PromoterFlanking_Hoffman.flanking.500 = col_double(),
    Promoter_UCSC = col_double(),
    Promoter_UCSC.flanking.500 = col_double(),
    Repressed_Hoffman = col_double(),
    Repressed_Hoffman.flanking.500 = col_double(),
    SuperEnhancer_Hnisz = col_double(),
    SuperEnhancer_Hnisz.flanking.500 = col_double(),
    TFBS_ENCODE = col_double(),
    TFBS_ENCODE.flanking.500 = col_double(),
    Transcr_Hoffman = col_double(),
    Transcr_Hoffman.flanking.500 = col_double(),
    TSS_Hoffman = col_double(),
    TSS_Hoffman.flanking.500 = col_double(),
    UTR_3_UCSC = col_double(),
    UTR_3_UCSC.flanking.500 = col_double(),
    UTR_5_UCSC = col_double(),
    UTR_5_UCSC.flanking.500 = col_double(),
    WeakEnhancer_Hoffman = col_double(),
    WeakEnhancer_Hoffman.flanking.500 = col_double(),
    GERP.NS = col_double(),
    GERP.RSsup4 = col_double(),
    MAFbin1 = col_double(),
    MAFbin2 = col_double(),
    MAFbin3 = col_double(),
    MAFbin4 = col_double(),
    MAFbin5 = col_double(),
    MAFbin6 = col_double(),
    MAFbin7 = col_double(),
    MAFbin8 = col_double(),
    MAFbin9 = col_double(),
    MAFbin10 = col_double(),
    MAF_Adj_Predicted_Allele_Age = col_double(),
    MAF_Adj_LLD_AFR = col_double(),
    Recomb_Rate_10kb = col_double(),
    Nucleotide_Diversity_10kb = col_double(),
    Backgrd_Selection_Stat = col_double(),
    CpG_Content_50kb = col_double(),
    MAF_Adj_ASMC = col_double(),
    GTEx_eQTL_MaxCPP = col_double(),
    BLUEPRINT_H3K27acQTL_MaxCPP = col_double(),
    BLUEPRINT_H3K4me1QTL_MaxCPP = col_double(),
    BLUEPRINT_DNA_methylation_MaxCPP = col_double(),
    synonymous = col_double(),
    non_synonymous = col_double(),
    Conserved_Vertebrate_phastCons46way = col_double(),
    Conserved_Vertebrate_phastCons46way.flanking.500 = col_double(),
    Conserved_Mammal_phastCons46way = col_double(),
    Conserved_Mammal_phastCons46way.flanking.500 = col_double(),
    Conserved_Primate_phastCons46way = col_double(),
    Conserved_Primate_phastCons46way.flanking.500 = col_double(),
    BivFlnk = col_double(),
    BivFlnk.flanking.500 = col_double(),
    Human_Promoter_Villar = col_double(),
    Human_Promoter_Villar.flanking.500 = col_double(),
    Human_Enhancer_Villar = col_double(),
    Human_Enhancer_Villar.flanking.500 = col_double(),
    Ancient_Sequence_Age_Human_Promoter = col_double(),
    Ancient_Sequence_Age_Human_Promoter.flanking.500 = col_double(),
    Ancient_Sequence_Age_Human_Enhancer = col_double(),
    Ancient_Sequence_Age_Human_Enhancer.flanking.500 = col_double(),
    Human_Enhancer_Villar_Species_Enhancer_Count = col_double(),
    Human_Promoter_Villar_ExAC = col_double(),
    Human_Promoter_Villar_ExAC.flanking.500 = col_double()
  )
#+END_SRC

#+BEGIN_SRC R :tangle ../scripts/check_ldscfiles.R

  file_df <- nest(file_df,feat_data = c(feature,path,annot_path))
  modify_cols <- function(cols,old,new) {
    cols$cols <- set_names(cols$cols, ~dplyr::if_else(.== old,new, .))
    return(cols)
  }


  feat_fun <- function(f,feat) {
    return(tibble::tibble(!!feat := scan(f,what = numeric(),skip = 1)))
    }


  pwalk(file_df,function(baseline_path, chrom, feat_data, new_path, new_annot_path,baseline_annot_path) {
    cat("Now on",chrom,"\n")
    keep_cols <- c("CHR","SNP","BP","baseL2",baseline_feat)

    bldcols <- names(spec_base$cols)
    bacols <- names(anno_cols$cols)
    stopifnot(all(keep_cols %in%  names(spec_base$cols)))
    stopifnot(all(keep_cols %in%  names(anno_cols$cols)))
    bad_good_cols <- keep_cols[!keep_cols %in%  names(anno_cols$cols)]
  
    bad_cols <- names(spec_base$cols)[!(names(spec_base$cols) %in% keep_cols)]
    bad_anno_cols <- str_replace(bad_cols,"L2$","")

    new_base <- spec_base
    new_anno_spec <- anno_cols
    for (bc in seq_along(bad_cols)) {
      new_base$cols[[bad_cols[bc]]] <- col_skip()
      new_anno_spec$cols[[bad_anno_cols[bc]]] <- col_skip()
    }
  
    feat_data <- mutate(feat_data,col_spec = map(feature, ~modify_cols(spec, "L2" , .x)))
    annot_df <- map2_dfc(feat_data$annot_path,feat_data$feature, ~feat_fun(.x, .y))
    o_anno_path <- bind_cols(vroom::vroom(baseline_annot_path,col_types = new_anno_spec,delim = "\t"),annot_df)
    tannot <- read_delim(feat_data$annot_path[1],delim = "\t")
    lddf <- pmap_dfc(feat_data,function(feature,path,col_spec, ...) {
      vroom::vroom(path,col_names = names(col_spec$cols),col_types = col_spec,delim = "\t",skip = 1L)})
    baseline_df <- bind_cols(vroom::vroom(baseline_path,delim = "\t",col_types = new_base),lddf)
    vroom::vroom_write(baseline_df,new_path,delim = "\t")
  })




om(baseline_path,delim = "\t",col_types = new_base),lddf)
    vroom::vroom_write(baseline_df,new_path,delim = "\t")
  })


#+END_SRC




#+BEGIN_SRC snakemake :tangle ../workflow/dl_snakefile


  def new_get_annot_files(wildcards):
      return {'anno_l2':expand(config_d['L2'] +"{annot}.{chrom}.l2.ldscore.gz",chrom=range(1,23),annot=all_annot['ptb_model'][wildcards.anno_name]),
              'baseline_l2':expand(config_d['L2'] +"baseline/baselineLD.{chrom}.l2.ldscore.gz",chrom=range(1,23)),
              'gwasf':config_d['GWAS'] +"ldsc_input/ptb_gwas.sumstats.gz",
              'baselinef':  expand(config_d['WEIGHTS'] +"weights.hm3_noMHC.{chrom}.l2.ldscore.gz",chrom=range(1,23)),
              'freqf':  expand(config_d['FRQF'] +"1000G.EUR.QC.{chrom}.frq",chrom=range(1,23)),
      }



  def get_merge_annot_files(wildcards):
      return {'anno_l2':expand(config_d['L2'] +"{annot}.{chrom}.l2.ldscore.gz",chrom=range(1,23),annot=all_annot['ptb_model'][wildcards.anno_name]),
              'annof':expand(config_d['L2'] +"{annot}.{chrom}.annot.gz",chrom=range(1,23),annot=all_annot['ptb_model'][wildcards.anno_name]),
              'baseline_l2':expand(config_d['L2'] +"baseline/baselineLD.{chrom}.l2.ldscore.gz",chrom=range(1,23))
        }

  rule merge_ldsc:
      input:
          unpack(get_merge_annot_files)   
      output:
          dataf=expand(config_d["L2"]+"new_baseline/{{anno_name}}.{chrom}.l2.ldscore.gz",chrom=range(1,23))
      params:
          L2=config_d['L2'],
          baseline_features=all_annot['baseline_model'],
          features=lambda wildcards: all_annot['ptb_model'][wildcards.anno_name],
          annot_name="{anno_name}"
      script:
          "../scripts/check_ldscfiles.R"

  rule run_ldsc:
      input:
          anno_ld=expand(config_d["L2"]+"new_baseline/{{anno_name}}.{chrom}.l2.ldscore.gz",chrom=range(1,23)),
          baselinef=  expand(config_d['WEIGHTS'] +"weights.hm3_noMHC.{chrom}.l2.ldscore.gz",chrom=range(1,23)),
          gwasf=config_d['GWAS'] +"ldsc_input/ptb_gwas.sumstats.gz"
      output:
          dataf="{anno_name}.results"
      log:
          tempf=temp("{anno_name}.log")
      params:
          annot=config_d["L2"]+"new_baseline/{anno_name}",
          weights=config_d['WEIGHTS']+"weights.hm3_noMHC.",
          frq=config_d['FRQF'] +"1000G.EUR.QC.",
          odir="{anno_name}"
      conda:
          config_e['ldsc']
      shell:
          """python2 ../ldsc.py --h2 {input.gwasf} --ref-ld-chr {params.annot} --w-ld-chr {params.weights} --overlap-annot --frqfile-chr {params.frq} --out {params.odir} """




#+END_SRC


#+END_SRC
